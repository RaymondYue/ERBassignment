import psycopg2
import csv
import os
import re
import pytz
from datetime import datetime, time, date
from input import csv_file_path, target_table, conn

# è®¾ç½®é¦™æ¸¯æ—¶åŒº
HONG_KONG_TZ = pytz.timezone('Asia/Hong_Kong')


def clean_data(value, data_type, col_name):
    """
    æ ¹æ®æ•°æ®åº“å­—æ®µç±»å‹æ¸…æ´—æ•°æ®

    å‚æ•°:
        value: åŸå§‹æ•°æ®å€¼
        data_type: PostgreSQLæ•°æ®ç±»å‹
        col_name: å­—æ®µåç§°

    è¿”å›:
        æ¸…æ´—åçš„å€¼
    """
    # å¤„ç†ç©ºå€¼
    if value == '' or value is None:
        return None

    try:
        # æ ¹æ®æ•°æ®ç±»å‹è¿›è¡Œæ¸…æ´—
        if 'int' in data_type or 'serial' in data_type:
            # æ•´å‹å¤„ç†
            return int(value) if value.strip() != '' else 0

        elif 'numeric' in data_type or 'real' in data_type or 'double' in data_type or 'float' in data_type:
            # æµ®ç‚¹æ•°å¤„ç†
            return float(value) if value.strip() != '' else 0.0

        elif 'bool' in data_type:
            # å¸ƒå°”å€¼å¤„ç†
            true_values = ['true', 't', 'yes', 'y', '1', 'æ˜¯']
            return value.lower() in true_values

        # ç‰¹åˆ«æ³¨æ„: å¤„ç†å¸¦æ—¶åŒºçš„æ—¶é—´æˆ³
        elif 'timestamp with time zone' in data_type.lower() or col_name == 'list_date':
            # æ—¶é—´æˆ³å¤„ç† (å¸¦æ—¶åŒº)
            try:
                # å°è¯•è§£æä¸ºå¸¦æ—¶åŒºçš„æ—¥æœŸæ—¶é—´
                dt = datetime.strptime(value, '%Y-%m-%d %H:%M:%S%z')
                if not dt.tzinfo:
                    # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œæ·»åŠ é¦™æ¸¯æ—¶åŒº
                    return HONG_KONG_TZ.localize(dt)
                return dt
            except:
                try:
                    # å°è¯•ISOæ ¼å¼
                    dt = datetime.fromisoformat(value)
                    if not dt.tzinfo:
                        return HONG_KONG_TZ.localize(dt)
                    return dt
                except:
                    # å°è¯•å…¶ä»–å¸¸è§æ ¼å¼
                    for fmt in ('%Y-%m-%dT%H:%M:%S', '%Y/%m/%d %H:%M:%S', '%d-%m-%Y %H:%M:%S',
                                '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M'):
                        try:
                            dt = datetime.strptime(value, fmt)
                            return HONG_KONG_TZ.localize(dt)
                        except:
                            continue
                    # ä½¿ç”¨å½“å‰æ—¶é—´ (å¸¦é¦™æ¸¯æ—¶åŒº)
                    return datetime.now(HONG_KONG_TZ)

        # å¤„ç†æ—¥æœŸå­—æ®µ
        elif 'date' in data_type.lower() or col_name == 'edit_date':
            # æ—¥æœŸå¤„ç†
            try:
                return datetime.strptime(value, '%Y-%m-%d').date()
            except:
                # å°è¯•å…¶ä»–å¸¸è§æ ¼å¼
                for fmt in ('%Y/%m/%d', '%d-%m-%Y', '%d/%m/%Y', '%m/%d/%Y'):
                    try:
                        return datetime.strptime(value, fmt).date()
                    except:
                        continue
                return date.today()  # é»˜è®¤ä»Šå¤©æ—¥æœŸ

        # å¤„ç†æ—¶é—´å­—æ®µ
        elif 'time' in data_type.lower() or 'hour' in col_name.lower():
            # æ—¶é—´å¤„ç†
            try:
                return datetime.strptime(value, '%H:%M:%S').time()
            except:
                # å°è¯•å…¶ä»–æ ¼å¼
                for fmt in ('%H:%M', '%I:%M %p', '%H:%M:%S.%f'):
                    try:
                        return datetime.strptime(value, fmt).time()
                    except:
                        continue
                return time(0, 0)  # é»˜è®¤åˆå¤œæ—¶é—´

        # å¤„ç†æ™®é€šæ—¶é—´æˆ³ (ä¸å¸¦æ—¶åŒº)
        elif 'timestamp' in data_type.lower():
            # æ—¶é—´æˆ³å¤„ç† (ä¸å¸¦æ—¶åŒº)
            try:
                return datetime.strptime(value, '%Y-%m-%d %H:%M:%S')
            except:
                # å°è¯•ISOæ ¼å¼å’Œå…¶ä»–å¸¸è§æ ¼å¼
                for fmt in ('%Y-%m-%dT%H:%M:%S', '%Y/%m/%d %H:%M:%S', '%d-%m-%Y %H:%M'):
                    try:
                        return datetime.strptime(value, fmt)
                    except:
                        continue
                return datetime.now()  # é»˜è®¤å½“å‰æ—¶é—´

        elif 'json' in data_type or 'jsonb' in data_type:
            # JSONå¤„ç†
            try:
                # å°è¯•è§£æJSON
                import json
                return json.loads(value)
            except:
                # è¿”å›ç©ºå­—å…¸
                return {}

        else:
            # æ–‡æœ¬ç±»å‹å¤„ç†
            # ç§»é™¤å¤šä½™ç©ºæ ¼å’Œä¸å¯è§å­—ç¬¦
            cleaned = re.sub(r'\s+', ' ', value).strip()

            # ç‰¹æ®Šå­—æ®µå¤„ç†
            if 'email' in col_name.lower():
                # åŸºæœ¬é‚®ç®±æ ¼å¼éªŒè¯
                if re.match(r'^[\w\.-]+@[\w\.-]+\.\w+$', cleaned):
                    return cleaned
                return 'invalid@example.com'

            elif 'phone' in col_name.lower() or 'tel' in col_name.lower():
                # ç§»é™¤éæ•°å­—å­—ç¬¦
                digits = re.sub(r'\D', '', cleaned)
                if len(digits) >= 10:
                    return digits[:15]
                return '0000000000'

            elif 'url' in col_name.lower() or 'website' in col_name.lower():
                # åŸºæœ¬URLéªŒè¯
                if re.match(r'^https?://', cleaned, re.IGNORECASE):
                    return cleaned
                return f'http://example.com/{cleaned[:50]}'

            return cleaned

    except Exception as e:
        print(f"âš ï¸ æ¸…æ´—æ•°æ®å¤±è´¥ - åˆ—: {col_name}, å€¼: '{value}', ç±»å‹: {data_type}, é”™è¯¯: {str(e)}")
        # æ ¹æ®ç±»å‹è¿”å›é»˜è®¤å€¼
        if 'int' in data_type:
            return 0
        elif 'float' in data_type or 'numeric' in data_type:
            return 0.0
        elif 'bool' in data_type:
            return False
        elif 'date' in data_type:
            return date.today()
        elif 'time' in data_type:
            return time(0, 0)
        elif 'timestamp' in data_type:
            return datetime.now(HONG_KONG_TZ) if 'time zone' in data_type.lower() else datetime.now()
        else:
            return 'INVALID_DATA'


def get_table_schema(conn, table_name):
    """
    è·å–è¡¨çš„å®Œæ•´ç»“æ„ä¿¡æ¯

    è¿”å›:
        dict: {åˆ—å: {'data_type': æ•°æ®ç±»å‹, 'is_nullable': æ˜¯å¦å…è®¸ç©ºå€¼}}
    """
    try:
        schema, table = table_name.split('.') if '.' in table_name else ('public', table_name)

        with conn.cursor() as cur:
            cur.execute(f"""
                SELECT column_name, udt_name, is_nullable, character_maximum_length
                FROM information_schema.columns
                WHERE table_schema = '{schema}' 
                AND table_name = '{table}'
            """)
            schema_info = {}
            for row in cur.fetchall():
                col_name, udt_name, is_nullable, max_length = row
                # å°†UDTåç§°æ˜ å°„åˆ°æ ‡å‡†æ•°æ®ç±»å‹
                if udt_name == 'timestamptz':
                    data_type = 'timestamp with time zone'
                elif udt_name == 'timestamp':
                    data_type = 'timestamp without time zone'
                elif udt_name == 'date':
                    data_type = 'date'
                elif udt_name == 'time':
                    data_type = 'time'
                else:
                    data_type = udt_name

                schema_info[col_name] = {
                    'data_type': data_type,
                    'is_nullable': is_nullable == 'YES',
                    'max_length': max_length
                }
            return schema_info
    except Exception as e:
        print(f"âŒ è·å–è¡¨ç»“æ„å¤±è´¥: {str(e)}")
        return {}


def upload_csv_to_table(conn, table_name, csv_path, delimiter=',', encoding='utf-8'):
    """
    å°†CSVæ–‡ä»¶æ•°æ®ä¸Šä¼ åˆ°PostgreSQLæ•°æ®åº“è¡¨ï¼ˆå¸¦æ•°æ®æ¸…æ´—ï¼‰

    å‚æ•°:
        conn: æ•°æ®åº“è¿æ¥å¯¹è±¡
        table_name: ç›®æ ‡è¡¨åï¼ˆåŒ…å«schemaï¼Œå¦‚public.table_nameï¼‰
        csv_path: CSVæ–‡ä»¶è·¯å¾„
        delimiter: CSVåˆ†éš”ç¬¦
        encoding: æ–‡ä»¶ç¼–ç 
    """
    try:
        # éªŒè¯CSVæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")

        # è·å–è¡¨ç»“æ„ä¿¡æ¯
        table_schema = get_table_schema(conn, table_name)
        if not table_schema:
            raise ValueError("æ— æ³•è·å–è¡¨ç»“æ„ä¿¡æ¯")

        with conn.cursor() as cur:
            # è·å–CSVæ–‡ä»¶åˆ—å
            with open(csv_path, 'r', encoding=encoding) as f:
                reader = csv.reader(f, delimiter=delimiter)
                header = next(reader)
                columns = header

            # æ£€æŸ¥CSVåˆ—æ˜¯å¦åœ¨æ•°æ®åº“ä¸­å­˜åœ¨
            missing_columns = [col for col in columns if col not in table_schema]
            if missing_columns:
                print(f"âš ï¸ è­¦å‘Š: CSVä¸­æœ‰æ•°æ®åº“ä¸å­˜åœ¨çš„åˆ—: {', '.join(missing_columns)}")
                # åªä¿ç•™æ•°æ®åº“å­˜åœ¨çš„åˆ—
                columns = [col for col in columns if col in table_schema]

            # ç”Ÿæˆåˆ—åå ä½ç¬¦
            col_names = ', '.join([f'"{col}"' for col in columns])
            placeholders = ', '.join(['%s'] * len(columns))

            # å‡†å¤‡æ’å…¥è¯­å¥
            sql = f"INSERT INTO {table_name} ({col_names}) VALUES ({placeholders})"

            # è¯»å–å¹¶ä¸Šä¼ æ•°æ®
            with open(csv_path, 'r', encoding=encoding) as f:
                reader = csv.reader(f, delimiter=delimiter)
                next(reader)  # è·³è¿‡æ ‡é¢˜è¡Œ

                # åˆ†æ‰¹ä¸Šä¼ ä»¥æé«˜æ€§èƒ½
                batch_size = 1000
                batch = []
                processed_rows = 0
                skipped_rows = 0

                for i, row in enumerate(reader):
                    try:
                        cleaned_row = []
                        for idx, value in enumerate(header):
                            if idx >= len(row):
                                # è¡Œæ•°æ®å°‘äºåˆ—æ•°
                                cell_value = ''
                            else:
                                cell_value = row[idx]

                            # åªå¤„ç†æ•°æ®åº“å­˜åœ¨çš„åˆ—
                            if value not in columns:
                                continue

                            col_info = table_schema[value]
                            data_type = col_info['data_type']
                            is_nullable = col_info['is_nullable']
                            max_length = col_info['max_length']

                            # æ¸…æ´—æ•°æ®
                            cleaned_value = clean_data(cell_value, data_type, value)

                            # å¤„ç†ç©ºå€¼
                            if cleaned_value is None and not is_nullable:
                                # æ ¹æ®åˆ—åæä¾›æ™ºèƒ½é»˜è®¤å€¼
                                if 'photo' in value.lower():
                                    cleaned_value = 'default_image.jpg'
                                elif 'date' in value.lower():
                                    cleaned_value = date.today()
                                elif 'time' in value.lower() or 'hour' in value.lower():
                                    cleaned_value = time(0, 0)
                                elif 'price' in value.lower() or 'amount' in value.lower():
                                    cleaned_value = 0
                                elif 'boolean' in value.lower() or value.lower().startswith('is_'):
                                    cleaned_value = False
                                else:
                                    cleaned_value = 'N/A'

                            # æ£€æŸ¥å­—ç¬¦ä¸²é•¿åº¦é™åˆ¶
                            if max_length and isinstance(cleaned_value, str) and len(cleaned_value) > max_length:
                                cleaned_value = cleaned_value[:max_length]

                            cleaned_row.append(cleaned_value)

                        # ç¡®ä¿æ¸…æ´—åçš„è¡Œé•¿åº¦ä¸åˆ—æ•°ä¸€è‡´
                        if len(cleaned_row) == len(columns):
                            batch.append(cleaned_row)
                            processed_rows += 1
                        else:
                            skipped_rows += 1
                            print(f"âš ï¸ è·³è¿‡è¡Œ {i + 2}: æ¸…æ´—ååˆ—æ•°ä¸åŒ¹é…")

                    except Exception as e:
                        skipped_rows += 1
                        print(f"âš ï¸ å¤„ç†è¡Œ {i + 2} å¤±è´¥: {str(e)}")
                        continue

                    # æ‰¹é‡æ’å…¥
                    if len(batch) >= batch_size:
                        try:
                            cur.executemany(sql, batch)
                            conn.commit()
                            batch = []
                            print(f"âœ“ å·²ä¸Šä¼  {processed_rows} è¡Œæ•°æ®...")
                        except Exception as e:
                            print(f"âŒ æ‰¹é‡æ’å…¥å¤±è´¥: {str(e)}")
                            conn.rollback()
                            # å°è¯•é€è¡Œæ’å…¥ä»¥å®šä½é—®é¢˜è¡Œ
                            for row_data in batch:
                                try:
                                    cur.execute(sql, row_data)
                                    conn.commit()
                                except Exception as e2:
                                    print(f"âŒ è¡Œæ’å…¥å¤±è´¥: {str(e2)}")
                                    print(f"    é—®é¢˜è¡Œæ•°æ®: {row_data}")
                                    conn.rollback()
                            batch = []

                # æ’å…¥å‰©ä½™æ•°æ®
                if batch:
                    try:
                        cur.executemany(sql, batch)
                        conn.commit()
                        print(f"âœ“ å·²ä¸Šä¼  {processed_rows} è¡Œæ•°æ®...")
                    except Exception as e:
                        print(f"âŒ æ‰¹é‡æ’å…¥å‰©ä½™æ•°æ®å¤±è´¥: {str(e)}")
                        conn.rollback()
                        # å°è¯•é€è¡Œæ’å…¥ä»¥å®šä½é—®é¢˜è¡Œ
                        for row_data in batch:
                            try:
                                cur.execute(sql, row_data)
                                conn.commit()
                            except Exception as e2:
                                print(f"âŒ è¡Œæ’å…¥å¤±è´¥: {str(e2)}")
                                print(f"    é—®é¢˜è¡Œæ•°æ®: {row_data}")
                                conn.rollback()

        print(f"âœ… æ•°æ®å¯¼å…¥å®Œæˆ! æˆåŠŸ: {processed_rows}, è·³è¿‡: {skipped_rows}")
        print(f"ğŸ“ è¡¨ '{table_name}' å·²æˆåŠŸå¯¼å…¥æ•°æ®")
        return True

    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}")
        conn.rollback()
        return False


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # conn = None
    try:
        # å»ºç«‹æ•°æ®åº“è¿æ¥
        # conn = psycopg2.connect(
        #     host="localhost",
        #     dbname="dishdb",
        #     user="postgres",
        #     password="1234"
        # )
        #
        # # # è®¾ç½®å‚æ•°
        # csv_file_path = "/Users/mac/Downloads/erbhomework/public.adminusers_adminuser_20250621_215118.csv"
        # target_table = "public.adminusers_adminuser"  # åŒ…å«schemaçš„è¡¨å


        # æ‰§è¡Œä¸Šä¼ 
        print("ğŸš€ å¼€å§‹å¯¼å…¥æ•°æ®...")
        success = upload_csv_to_table(
            conn,
            table_name=target_table,
            csv_path=csv_file_path,
            delimiter=',',
            encoding='utf-8'
        )

        if success:
            # éªŒè¯ä¸Šä¼ è¡Œæ•°
            with conn.cursor() as cur:
                cur.execute(f"SELECT COUNT(*) FROM {target_table}")
                count = cur.fetchone()[0]
                print(f"ğŸ“Š è¡¨ {target_table} ç°åœ¨å…±æœ‰ {count} æ¡è®°å½•")

    except Exception as e:
        print(f"âŒ ä¸»ç¨‹åºé”™è¯¯: {str(e)}")
    finally:
        # å…³é—­æ•°æ®åº“è¿æ¥
        if conn:
            conn.close()